# Open CLIP CoCa model inference

OpenCLIP CoCa (Contrastive Captioner) model allows to generate text a description of an image.
The model is build with two transformers that share embedding space. 

During the inference the image is first transformed into embedding, then the text is generated
using attention network. The text is generated by tokens (words) and the best result is selected 
rather by having the higher probability or using a beam search algorithm.  

## Contents
 * `open_clip_coca_inference.py` - Open CLIP CoCa inference adapted for CPU / CUDA / Ascend NPU

## How to run
 1. Install dependencies:
    * CPU - `pip install -r requirements_cpu.txt`
    * CUDA - `pip install -r requirements_cuda.txt`
    * NPU - `pip install -r requirements_npu.txt` (you may need a specific version of python 
      since `onnxruntime-cann` is not available for all python versions / platforms)

 2. Export the model to ONNX format:
    `python export_to_onnx.py --exporter dynamo`
    The script creates 2 ONNX models: one for image transformer and the other for text generator. 

 3. Run the inference:
    * CPU - `python open_clip_coca_inference.py --img bus.jpg`
    * CUDA - `python open_clip_coca_inference.py --img bus.jpg --device cuda`
    * NPU - `python open_clip_coca_inference.py --img bus.jpg --device npu --runtime pytorch`


## CLI

```
$ python export_to_onnx.py --help
usage: export_to_onnx.py [-h] [--exporter {dynamo,legacy}] [--backport]

options:
  -h, --help            show this help message and exit
  --exporter {dynamo,legacy}
                        What exporter to use.
  --backport            Backport model to opset 15 (only used for dynamo exporter).
```

```
$ python open_clip_coca_inference.py --help
usage: open_clip_coca_inference.py [-h] --img IMG [--device DEVICE] [--runtime {onnx,pytorch}] [--len LEN]
                                   [--generation_type {beam_search,top_k,top_p}] [--verbose]

options:
  -h, --help            show this help message and exit
  --img IMG             Path to input image.
  --device DEVICE       Device to use for tensor operations.
  --runtime {onnx,pytorch}
                        A runtime to use.
  --len LEN             A max length of a generated text.
  --generation_type {beam_search,top_k,top_p}
                        Algorithm to select the best generated output.
  --verbose             Enable verbose logging.
```
